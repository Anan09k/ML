{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35789bec-7a5b-485a-a27a-c52733b67615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7f268a-c04a-4320-b5a8-4556a02fd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuruing path to kaggle json file\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Ensuring the folder for Kaggle exists\n",
    "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "\n",
    "# Moving the kaggle.json file to the ~/.kaggle/ directory\n",
    "with open('kaggle.json', 'r') as f:\n",
    "    creds = json.load(f)\n",
    "\n",
    "# Creating the kaggle.json in the ~/.kaggle directory\n",
    "with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
    "    json.dump(creds, f)\n",
    "\n",
    "# Setting the appropriate file permissions\n",
    "os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b112449-c747-41e5-a23f-0396ad485a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
      "License(s): other\n",
      "sentiment140.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "# Using API to fetch dataset from Kaggle\n",
    "! kaggle datasets download -d kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c1ec66-1ba0-4c4e-a094-f58556b1f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is extracted\n"
     ]
    }
   ],
   "source": [
    "# Extracting the compressed dataset\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('sentiment140.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    print(\"The dataset is extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad38750-85bd-4881-a121-05215103cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kukre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f196d80d-257f-4853-8922-1bd802c1a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Printing the stopwords in English\n",
    "print(stopwords.words(\"English\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605497b-7e78-45de-9d45-ca8eadfb9e8f",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ce3f2f-34e8-43ac-8b5a-738b92c7b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv(r\"C:\\Users\\kukre\\OneDrive\\Documents\\Season Of AI\\training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8641150b-a807-496d-b748-b65c72a95905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c40182c-291b-4801-914a-91e88754f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3d43219-244e-4976-9294-f2ec6ff38d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First datapoint is taken as column names, so creating new list for original column names\n",
    "data.columns=[\"target\",\"ids\",\"date\",\"flag\", \"user\",\"text\"]\n",
    "\n",
    "# Loading data again\n",
    "data = pd.read_csv(r\"C:\\Users\\kukre\\OneDrive\\Documents\\Season Of AI\\training.1600000.processed.noemoticon.csv\",names=data.columns, encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dacc29e2-ff6e-47db-97fa-aa28c5b167b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b83fb8e-f395-460f-9231-ab69cc8bc533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ba71cc5-1afc-459c-8a0c-a8d5389e5c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "ids       0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3d63549-8685-4d7a-a28f-f243f145966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bcec72b-b8b1-40f5-b3c5-97b609759e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking distributuion of target column\n",
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92909baf-5dc7-48df-af3c-a3e0f934c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kukre\\AppData\\Local\\Temp\\ipykernel_9108\\1497698820.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['target'].replace(4, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Changing label \"4\" to \"1\"\n",
    "data['target'].replace(4, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab82d7f-9ad8-445a-a59b-29c60fb92568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06973e-33d4-4e11-81fa-a8860ee2572d",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79c6e009-b12f-48a4-a607-436edd95b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28906309-1516-48ed-8f1a-7589ee58ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to reduce each word to it's root word\n",
    "def stemming(content):\n",
    "    stemmed_content=re.sub(\"[^a-zA-Z]\", \" \", content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words(\"english\")]\n",
    "    stemmed_content = \" \".join(stemmed_content)\n",
    "    return stemmed_content\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801b1a2-42b4-4cd5-ac02-434d280a85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function to the text column of the dataset\n",
    "data[\"stemmed_text\"]=data[\"text\"].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6391c52-2e9c-4047-a25a-c9c236ce7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51437c94-0bd0-438a-99b1-1355af18f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b34ec4-78da-47b5-b5f7-8c315da50193",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b09aa-44c7-4cd1-b8e8-bdda8b5d9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating features and label\n",
    "features = data[\"stemmed_text\"].values\n",
    "label = data[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bc472-3b4d-4974-b734-9eb833daac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features,label,test_size=0.2, random_state = 2, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85aa126-e1e7-4cd3-a4a0-c7d124014cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the textual data to numerical data for computation by the model\n",
    "vectorizer=TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ec018d-b32c-4dfe-9495-fee44465ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f694f72-fe39-4596-82a2-40dea26d2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06444aba-39fe-4f69-8b68-6d6fe2a09716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is a binary classification problem, use LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression()\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d1085-5a45-4125-b49e-5ab4cfb37670",
   "metadata": {},
   "source": [
    "# Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16bfa57-935a-4705-990c-176301cbf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score for training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train,X_train_prediction)\n",
    "print(\"Accuracy score of training data:\", training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a79e30-322b-4b9b-ac05-5a78970a2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score for testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(Y_test,X_test_prediction)\n",
    "print(\"Accuracy score of testing data:\", test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad5d3e-db2d-46ea-8719-03cb58769b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since model is overfitted, try bagging to achieve a generalised model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b7361-069e-4f10-aeb6-0df6c0268ea6",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73643b6c-0e15-4f2d-985a-0adbff69f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "algo = LogisticRegression()\n",
    "\n",
    "ensembleModel = BaggingClassifier(n_estimators=42, base_estimator=algo)\n",
    "\n",
    "ensembleModel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2285827-81a7-422f-b0f5-ba887f73975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score for training data\n",
    "X_train_prediction_bagging = ensembleModel.predict(X_train)\n",
    "training_data_accuracy_bagging = accuracy_score(Y_train,X_train_prediction_bagging)\n",
    "print(\"Accuracy score of training data:\", training_data_accuracy_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f329c-3e1c-465d-bf5d-f91155a34d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score for testing data\n",
    "X_test_prediction_bagging = ensebleModel.predict(X_test)\n",
    "test_data_accuracy_bagging = accuracy_score(Y_test,X_test_prediction_bagging)\n",
    "print(\"Accuracy score of testing data:\", test_data_accuracy_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace1c10-cef5-430a-b9fa-f0535b7bd7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916a5bf3-e66a-4b9c-968b-8ec924e6d3d4",
   "metadata": {},
   "source": [
    "# Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc377c8f-a319-4e1d-8802-bec1f831cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efdd20-a8d1-4a6e-bd69-c8a9f63e03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= \"twitter_sentiment_analysis_model.sav\"\n",
    "pickle.dump(model,open(filename,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d6d78-17eb-47aa-96e1-42bd1610ae4c",
   "metadata": {},
   "source": [
    "# Using the saved model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672a431-1afb-43bc-af4f-7935d56ea233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "loaded_model = pickle.load(open(\"twitter_sentiment_analysis_model.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2dd68-c054-45f4-b5eb-0a4957487620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134686ab-b298-4c9a-b028-85fde8ea3a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
